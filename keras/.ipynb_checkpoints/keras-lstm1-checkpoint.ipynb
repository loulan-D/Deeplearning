{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "用conda 创建python虚拟环境\n",
    "conda -v   conda版本\n",
    "conda list  查看安装包\n",
    "conda env list   查看当前存在的虚拟环境\n",
    "conda update conda 检查更新当前conda\n",
    "conda create -n env_name python==x.x   创建python虚拟环境\n",
    "source activate env_name   激活虚拟环境\n",
    "conda install -n env_name [package] 安装包\n",
    "source deactivate     关闭虚拟环境\n",
    "conda remove -n env_name --all    删除虚拟环境\n",
    "conda remove --name env_name  package_name  删除环境中的某个包\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Keras学习lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导包\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 把字母表转化为keras可以处理的方式\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "# create the mapping of characters to integers and the reverse\n",
    "char_to_int = dict((c,i) for i,c in enumerate(alphabet))\n",
    "int_to_char = dict((i,c) for i,c in enumerate(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 创建一个数据集，通过几个字母预测下一个字母是什么\n",
    "seq_length = 3\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0,len(alphabet)-seq_length,1):\n",
    "    seq_in = alphabet[i:i+seq_length]\n",
    "    seq_out = alphabet[i+seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "#     print(seq_in,'-->',seq_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " - 2s - loss: 3.2663 - acc: 0.0435\n",
      "Epoch 2/150\n",
      " - 0s - loss: 3.2527 - acc: 0.0435\n",
      "Epoch 3/150\n",
      " - 0s - loss: 3.2451 - acc: 0.0870\n",
      "Epoch 4/150\n",
      " - 0s - loss: 3.2376 - acc: 0.0435\n",
      "Epoch 5/150\n",
      " - 0s - loss: 3.2296 - acc: 0.0435\n",
      "Epoch 6/150\n",
      " - 0s - loss: 3.2213 - acc: 0.0435\n",
      "Epoch 7/150\n",
      " - 0s - loss: 3.2119 - acc: 0.0435\n",
      "Epoch 8/150\n",
      " - 0s - loss: 3.2004 - acc: 0.0000e+00\n",
      "Epoch 9/150\n",
      " - 0s - loss: 3.1890 - acc: 0.0435\n",
      "Epoch 10/150\n",
      " - 0s - loss: 3.1733 - acc: 0.0435\n",
      "Epoch 11/150\n",
      " - 0s - loss: 3.1573 - acc: 0.0000e+00\n",
      "Epoch 12/150\n",
      " - 0s - loss: 3.1380 - acc: 0.0435\n",
      "Epoch 13/150\n",
      " - 0s - loss: 3.1157 - acc: 0.0000e+00\n",
      "Epoch 14/150\n",
      " - 0s - loss: 3.0901 - acc: 0.0435\n",
      "Epoch 15/150\n",
      " - 0s - loss: 3.0691 - acc: 0.0000e+00\n",
      "Epoch 16/150\n",
      " - 0s - loss: 3.0457 - acc: 0.0435\n",
      "Epoch 17/150\n",
      " - 0s - loss: 3.0194 - acc: 0.0870\n",
      "Epoch 18/150\n",
      " - 0s - loss: 2.9955 - acc: 0.0870\n",
      "Epoch 19/150\n",
      " - 0s - loss: 2.9713 - acc: 0.1304\n",
      "Epoch 20/150\n",
      " - 0s - loss: 2.9414 - acc: 0.1304\n",
      "Epoch 21/150\n",
      " - 0s - loss: 2.9179 - acc: 0.0870\n",
      "Epoch 22/150\n",
      " - 0s - loss: 2.8840 - acc: 0.0435\n",
      "Epoch 23/150\n",
      " - 0s - loss: 2.8535 - acc: 0.0870\n",
      "Epoch 24/150\n",
      " - 0s - loss: 2.8212 - acc: 0.0870\n",
      "Epoch 25/150\n",
      " - 0s - loss: 2.7865 - acc: 0.0870\n",
      "Epoch 26/150\n",
      " - 0s - loss: 2.7597 - acc: 0.0435\n",
      "Epoch 27/150\n",
      " - 0s - loss: 2.7248 - acc: 0.0870\n",
      "Epoch 28/150\n",
      " - 0s - loss: 2.6925 - acc: 0.0435\n",
      "Epoch 29/150\n",
      " - 0s - loss: 2.6675 - acc: 0.0435\n",
      "Epoch 30/150\n",
      " - 0s - loss: 2.6399 - acc: 0.0435\n",
      "Epoch 31/150\n",
      " - 0s - loss: 2.6108 - acc: 0.0435\n",
      "Epoch 32/150\n",
      " - 0s - loss: 2.5896 - acc: 0.0435\n",
      "Epoch 33/150\n",
      " - 0s - loss: 2.5645 - acc: 0.0435\n",
      "Epoch 34/150\n",
      " - 0s - loss: 2.5423 - acc: 0.0435\n",
      "Epoch 35/150\n",
      " - 0s - loss: 2.5229 - acc: 0.0870\n",
      "Epoch 36/150\n",
      " - 0s - loss: 2.5014 - acc: 0.0435\n",
      "Epoch 37/150\n",
      " - 0s - loss: 2.4839 - acc: 0.0870\n",
      "Epoch 38/150\n",
      " - 0s - loss: 2.4598 - acc: 0.0870\n",
      "Epoch 39/150\n",
      " - 0s - loss: 2.4384 - acc: 0.0870\n",
      "Epoch 40/150\n",
      " - 0s - loss: 2.4193 - acc: 0.0870\n",
      "Epoch 41/150\n",
      " - 0s - loss: 2.3986 - acc: 0.0435\n",
      "Epoch 42/150\n",
      " - 0s - loss: 2.3786 - acc: 0.0870\n",
      "Epoch 43/150\n",
      " - 0s - loss: 2.3564 - acc: 0.0870\n",
      "Epoch 44/150\n",
      " - 0s - loss: 2.3267 - acc: 0.1304\n",
      "Epoch 45/150\n",
      " - 0s - loss: 2.3020 - acc: 0.1739\n",
      "Epoch 46/150\n",
      " - 0s - loss: 2.2801 - acc: 0.1739\n",
      "Epoch 47/150\n",
      " - 0s - loss: 2.2555 - acc: 0.1739\n",
      "Epoch 48/150\n",
      " - 0s - loss: 2.2294 - acc: 0.2174\n",
      "Epoch 49/150\n",
      " - 0s - loss: 2.2123 - acc: 0.2174\n",
      "Epoch 50/150\n",
      " - 0s - loss: 2.1920 - acc: 0.1739\n",
      "Epoch 51/150\n",
      " - 0s - loss: 2.1736 - acc: 0.1304\n",
      "Epoch 52/150\n",
      " - 0s - loss: 2.1449 - acc: 0.1739\n",
      "Epoch 53/150\n",
      " - 0s - loss: 2.1298 - acc: 0.1304\n",
      "Epoch 54/150\n",
      " - 0s - loss: 2.1095 - acc: 0.1739\n",
      "Epoch 55/150\n",
      " - 0s - loss: 2.0881 - acc: 0.1739\n",
      "Epoch 56/150\n",
      " - 0s - loss: 2.0763 - acc: 0.2174\n",
      "Epoch 57/150\n",
      " - 0s - loss: 2.0588 - acc: 0.3043\n",
      "Epoch 58/150\n",
      " - 0s - loss: 2.0403 - acc: 0.2174\n",
      "Epoch 59/150\n",
      " - 0s - loss: 2.0308 - acc: 0.2174\n",
      "Epoch 60/150\n",
      " - 0s - loss: 2.0168 - acc: 0.2174\n",
      "Epoch 61/150\n",
      " - 0s - loss: 1.9903 - acc: 0.2609\n",
      "Epoch 62/150\n",
      " - 0s - loss: 1.9805 - acc: 0.3043\n",
      "Epoch 63/150\n",
      " - 0s - loss: 1.9630 - acc: 0.3043\n",
      "Epoch 64/150\n",
      " - 0s - loss: 1.9487 - acc: 0.3043\n",
      "Epoch 65/150\n",
      " - 0s - loss: 1.9327 - acc: 0.3478\n",
      "Epoch 66/150\n",
      " - 0s - loss: 1.9201 - acc: 0.2609\n",
      "Epoch 67/150\n",
      " - 0s - loss: 1.9023 - acc: 0.3043\n",
      "Epoch 68/150\n",
      " - 0s - loss: 1.8870 - acc: 0.3913\n",
      "Epoch 69/150\n",
      " - 0s - loss: 1.8762 - acc: 0.3478\n",
      "Epoch 70/150\n",
      " - 0s - loss: 1.8641 - acc: 0.3478\n",
      "Epoch 71/150\n",
      " - 0s - loss: 1.8437 - acc: 0.3478\n",
      "Epoch 72/150\n",
      " - 0s - loss: 1.8337 - acc: 0.3478\n",
      "Epoch 73/150\n",
      " - 0s - loss: 1.8220 - acc: 0.3043\n",
      "Epoch 74/150\n",
      " - 0s - loss: 1.8115 - acc: 0.3913\n",
      "Epoch 75/150\n",
      " - 0s - loss: 1.7983 - acc: 0.3043\n",
      "Epoch 76/150\n",
      " - 0s - loss: 1.7813 - acc: 0.3913\n",
      "Epoch 77/150\n",
      " - 0s - loss: 1.7711 - acc: 0.4348\n",
      "Epoch 78/150\n",
      " - 0s - loss: 1.7616 - acc: 0.4348\n",
      "Epoch 79/150\n",
      " - 0s - loss: 1.7476 - acc: 0.4783\n",
      "Epoch 80/150\n",
      " - 0s - loss: 1.7355 - acc: 0.3913\n",
      "Epoch 81/150\n",
      " - 0s - loss: 1.7306 - acc: 0.2609\n",
      "Epoch 82/150\n",
      " - 0s - loss: 1.7129 - acc: 0.5217\n",
      "Epoch 83/150\n",
      " - 0s - loss: 1.7051 - acc: 0.3478\n",
      "Epoch 84/150\n",
      " - 0s - loss: 1.6954 - acc: 0.5217\n",
      "Epoch 85/150\n",
      " - 0s - loss: 1.6919 - acc: 0.3913\n",
      "Epoch 86/150\n",
      " - 0s - loss: 1.6698 - acc: 0.4348\n",
      "Epoch 87/150\n",
      " - 0s - loss: 1.6635 - acc: 0.5652\n",
      "Epoch 88/150\n",
      " - 0s - loss: 1.6570 - acc: 0.4783\n",
      "Epoch 89/150\n",
      " - 0s - loss: 1.6528 - acc: 0.4348\n",
      "Epoch 90/150\n",
      " - 0s - loss: 1.6351 - acc: 0.6087\n",
      "Epoch 91/150\n",
      " - 0s - loss: 1.6252 - acc: 0.6522\n",
      "Epoch 92/150\n",
      " - 0s - loss: 1.6165 - acc: 0.6522\n",
      "Epoch 93/150\n",
      " - 0s - loss: 1.6067 - acc: 0.5652\n",
      "Epoch 94/150\n",
      " - 0s - loss: 1.5964 - acc: 0.5652\n",
      "Epoch 95/150\n",
      " - 0s - loss: 1.5919 - acc: 0.5652\n",
      "Epoch 96/150\n",
      " - 0s - loss: 1.5904 - acc: 0.5217\n",
      "Epoch 97/150\n",
      " - 0s - loss: 1.5762 - acc: 0.4783\n",
      "Epoch 98/150\n",
      " - 0s - loss: 1.5650 - acc: 0.5652\n",
      "Epoch 99/150\n",
      " - 0s - loss: 1.5577 - acc: 0.5652\n",
      "Epoch 100/150\n",
      " - 0s - loss: 1.5485 - acc: 0.6522\n",
      "Epoch 101/150\n",
      " - 0s - loss: 1.5480 - acc: 0.5652\n",
      "Epoch 102/150\n",
      " - 0s - loss: 1.5343 - acc: 0.5652\n",
      "Epoch 103/150\n",
      " - 0s - loss: 1.5239 - acc: 0.6087\n",
      "Epoch 104/150\n",
      " - 0s - loss: 1.5140 - acc: 0.7391\n",
      "Epoch 105/150\n",
      " - 0s - loss: 1.5113 - acc: 0.6957\n",
      "Epoch 106/150\n",
      " - 0s - loss: 1.4985 - acc: 0.6957\n",
      "Epoch 107/150\n",
      " - 0s - loss: 1.4961 - acc: 0.5217\n",
      "Epoch 108/150\n",
      " - 0s - loss: 1.4877 - acc: 0.6957\n",
      "Epoch 109/150\n",
      " - 0s - loss: 1.4796 - acc: 0.6522\n",
      "Epoch 110/150\n",
      " - 0s - loss: 1.4656 - acc: 0.7826\n",
      "Epoch 111/150\n",
      " - 0s - loss: 1.4606 - acc: 0.6522\n",
      "Epoch 112/150\n",
      " - 0s - loss: 1.4507 - acc: 0.6522\n",
      "Epoch 113/150\n",
      " - 0s - loss: 1.4493 - acc: 0.7826\n",
      "Epoch 114/150\n",
      " - 0s - loss: 1.4376 - acc: 0.7826\n",
      "Epoch 115/150\n",
      " - 0s - loss: 1.4356 - acc: 0.7391\n",
      "Epoch 116/150\n",
      " - 0s - loss: 1.4208 - acc: 0.6957\n",
      "Epoch 117/150\n",
      " - 0s - loss: 1.4159 - acc: 0.7826\n",
      "Epoch 118/150\n",
      " - 0s - loss: 1.4087 - acc: 0.7391\n",
      "Epoch 119/150\n",
      " - 0s - loss: 1.4044 - acc: 0.7391\n",
      "Epoch 120/150\n",
      " - 0s - loss: 1.3994 - acc: 0.7391\n",
      "Epoch 121/150\n",
      " - 0s - loss: 1.3912 - acc: 0.7391\n",
      "Epoch 122/150\n",
      " - 0s - loss: 1.3765 - acc: 0.7391\n",
      "Epoch 123/150\n",
      " - 0s - loss: 1.3863 - acc: 0.6522\n",
      "Epoch 124/150\n",
      " - 0s - loss: 1.3714 - acc: 0.7826\n",
      "Epoch 125/150\n",
      " - 0s - loss: 1.3660 - acc: 0.7391\n",
      "Epoch 126/150\n",
      " - 0s - loss: 1.3512 - acc: 0.7826\n",
      "Epoch 127/150\n",
      " - 0s - loss: 1.3429 - acc: 0.7391\n",
      "Epoch 128/150\n",
      " - 0s - loss: 1.3392 - acc: 0.7826\n",
      "Epoch 129/150\n",
      " - 0s - loss: 1.3364 - acc: 0.7826\n",
      "Epoch 130/150\n",
      " - 0s - loss: 1.3278 - acc: 0.8261\n",
      "Epoch 131/150\n",
      " - 0s - loss: 1.3218 - acc: 0.8261\n",
      "Epoch 132/150\n",
      " - 0s - loss: 1.3137 - acc: 0.8261\n",
      "Epoch 133/150\n",
      " - 0s - loss: 1.3133 - acc: 0.8261\n",
      "Epoch 134/150\n",
      " - 0s - loss: 1.3052 - acc: 0.8261\n",
      "Epoch 135/150\n",
      " - 0s - loss: 1.3030 - acc: 0.8261\n",
      "Epoch 136/150\n",
      " - 0s - loss: 1.2990 - acc: 0.8696\n",
      "Epoch 137/150\n",
      " - 0s - loss: 1.2817 - acc: 0.8696\n",
      "Epoch 138/150\n",
      " - 0s - loss: 1.2753 - acc: 0.8696\n",
      "Epoch 139/150\n",
      " - 0s - loss: 1.2764 - acc: 0.7826\n",
      "Epoch 140/150\n",
      " - 0s - loss: 1.2684 - acc: 0.8261\n",
      "Epoch 141/150\n",
      " - 0s - loss: 1.2690 - acc: 0.8261\n",
      "Epoch 142/150\n",
      " - 0s - loss: 1.2577 - acc: 0.8261\n",
      "Epoch 143/150\n",
      " - 0s - loss: 1.2593 - acc: 0.8261\n",
      "Epoch 144/150\n",
      " - 0s - loss: 1.2452 - acc: 0.8261\n",
      "Epoch 145/150\n",
      " - 0s - loss: 1.2369 - acc: 0.7826\n",
      "Epoch 146/150\n",
      " - 0s - loss: 1.2376 - acc: 0.8261\n",
      "Epoch 147/150\n",
      " - 0s - loss: 1.2280 - acc: 0.8261\n",
      "Epoch 148/150\n",
      " - 0s - loss: 1.2277 - acc: 0.8261\n",
      "Epoch 149/150\n",
      " - 0s - loss: 1.2194 - acc: 0.8261\n",
      "Epoch 150/150\n",
      " - 0s - loss: 1.2113 - acc: 0.8261\n",
      "Model accuracy: 82.61\n",
      "['A', 'B', 'C'] -> D\n",
      "['B', 'C', 'D'] -> D\n",
      "['C', 'D', 'E'] -> F\n",
      "['D', 'E', 'F'] -> G\n",
      "['E', 'F', 'G'] -> H\n",
      "['F', 'G', 'H'] -> I\n",
      "['G', 'H', 'I'] -> J\n",
      "['H', 'I', 'J'] -> K\n",
      "['I', 'J', 'K'] -> L\n",
      "['J', 'K', 'L'] -> M\n",
      "['K', 'L', 'M'] -> N\n",
      "['L', 'M', 'N'] -> O\n",
      "['M', 'N', 'O'] -> P\n",
      "['N', 'O', 'P'] -> Q\n",
      "['O', 'P', 'Q'] -> R\n",
      "['P', 'Q', 'R'] -> S\n",
      "['Q', 'R', 'S'] -> T\n",
      "['R', 'S', 'T'] -> U\n",
      "['S', 'T', 'U'] -> V\n",
      "['T', 'U', 'V'] -> X\n",
      "['U', 'V', 'W'] -> Y\n",
      "['V', 'W', 'X'] -> Y\n",
      "['W', 'X', 'Y'] -> Y\n"
     ]
    }
   ],
   "source": [
    "# 转换datax的格式 reshape x to be[samples ,time steps,features]\n",
    "X = np.reshape(dataX,(len(dataX),seq_length,1))\n",
    "# normalize   归一化到0-1\n",
    "X = X/ float(len(alphabet))\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "# create and fit the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32,input_shape=(X.shape[1],X.shape[2])))\n",
    "model.add(Dense(y.shape[1],activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "model.fit(X,y,epochs=150,batch_size = 1,verbose = 2)\n",
    "# performance of the model\n",
    "scores = model.evaluate(X,y,verbose = 0)\n",
    "print(\"Model accuracy: %.2f\"%(scores[1]*100))\n",
    "# demonstrate some model predictions\n",
    "for pattern in dataX:\n",
    "    x = np.reshape(pattern,(1,len(pattern),1))\n",
    "    x = x/float(len(alphabet))\n",
    "    prediction = model.predict(x,verbose = 0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in,'->',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
